{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T11:41:58.882550Z","iopub.status.busy":"2024-04-16T11:41:58.881424Z","iopub.status.idle":"2024-04-16T11:41:58.890313Z","shell.execute_reply":"2024-04-16T11:41:58.889210Z","shell.execute_reply.started":"2024-04-16T11:41:58.882514Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import matplotlib.pyplot as plt\n","import time\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T11:41:58.892601Z","iopub.status.busy":"2024-04-16T11:41:58.892152Z","iopub.status.idle":"2024-04-16T11:42:33.474086Z","shell.execute_reply":"2024-04-16T11:42:33.473260Z","shell.execute_reply.started":"2024-04-16T11:41:58.892568Z"},"trusted":true},"outputs":[],"source":["train_dataset, val_dataset = keras.utils.image_dataset_from_directory(\n","    'New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train',\n","    labels='inferred',\n","    label_mode='int',\n","    class_names=None,\n","    color_mode='rgb',\n","    batch_size=32,\n","    image_size=(224, 224),\n","    shuffle=True,\n","    seed=42,\n","    validation_split=0.2,\n","    subset='both'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T11:42:35.146316Z","iopub.status.busy":"2024-04-16T11:42:35.146068Z","iopub.status.idle":"2024-04-16T11:42:35.152462Z","shell.execute_reply":"2024-04-16T11:42:35.151707Z","shell.execute_reply.started":"2024-04-16T11:42:35.146295Z"},"trusted":true},"outputs":[],"source":["train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n","val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T11:42:35.155235Z","iopub.status.busy":"2024-04-16T11:42:35.154958Z","iopub.status.idle":"2024-04-16T11:42:36.877116Z","shell.execute_reply":"2024-04-16T11:42:36.876015Z","shell.execute_reply.started":"2024-04-16T11:42:35.155207Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(10, 10))\n","for images, labels in train_dataset.take(1):\n","    for i in range(9):\n","        ax = plt.subplot(3, 3, i + 1)\n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\n","        plt.title(int(labels[i]))\n","        plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T11:42:36.878544Z","iopub.status.busy":"2024-04-16T11:42:36.878235Z","iopub.status.idle":"2024-04-16T11:42:36.883022Z","shell.execute_reply":"2024-04-16T11:42:36.881913Z","shell.execute_reply.started":"2024-04-16T11:42:36.878518Z"},"trusted":true},"outputs":[],"source":["num_classes = 38\n","image_size = (224, 224, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T11:42:36.884535Z","iopub.status.busy":"2024-04-16T11:42:36.884248Z","iopub.status.idle":"2024-04-16T11:42:36.900974Z","shell.execute_reply":"2024-04-16T11:42:36.900086Z","shell.execute_reply.started":"2024-04-16T11:42:36.884488Z"},"trusted":true},"outputs":[],"source":["def make_alexnet_model(input_shape, num_classes):\n","    inputs = keras.Input(shape=input_shape)\n","\n","    # Layer 1: Convolutional + Max Pooling\n","#     x = data_augmentation(inputs)\n","    x = layers.Rescaling(1.0 / 255)(inputs)\n","    x = layers.Conv2D(32, (3, 3), strides=(4, 4), activation='relu', padding='valid')(inputs)\n","    x = layers.MaxPooling2D((3, 3), strides=(2,2))(x)\n","    x = layers.BatchNormalization()(x)\n","\n","    # Layer 2: Convolutional + Max Pooling\n","    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.MaxPooling2D((3, 3), strides=(2,2))(x)\n","    x = layers.BatchNormalization()(x)\n","\n","    # Layer 3: Three Convolutional Layers\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","\n","    # Layer 4: Max Pooling\n","    x = layers.MaxPooling2D((3, 3), strides=(2,2))(x)\n","\n","    # Flatten and Fully Connected Layers\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(4096, activation='relu')(x)\n","    x = layers.Dropout(0.5)(x)\n","    x = layers.Dense(4096, activation='relu')(x)\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(num_classes, activation='softmax')(x)\n","    \n","    return keras.Model(inputs, outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T11:42:36.902906Z","iopub.status.busy":"2024-04-16T11:42:36.902495Z","iopub.status.idle":"2024-04-16T11:42:36.923145Z","shell.execute_reply":"2024-04-16T11:42:36.922283Z","shell.execute_reply.started":"2024-04-16T11:42:36.902875Z"},"trusted":true},"outputs":[],"source":["def make_vgg16_model(input_shape, num_classes):\n","    inputs = keras.Input(shape=input_shape)\n","\n","    # Block 1\n","   # x = data_augmentation(inputs)\n","    x = layers.Rescaling(1.0 / 255)(inputs)\n","    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","\n","    # Block 2\n","    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","\n","    # Block 3\n","    x = layers.Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","\n","    # Block 4\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","\n","    # Block 5\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","\n","    # Flatten and Fully Connected Layers\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(4096, activation='relu')(x)\n","    x = layers.Dropout(0.5)(x)\n","    x = layers.Dense(4096, activation='relu')(x)\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(num_classes, activation='softmax')(x)\n","\n","    return keras.Model(inputs, outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T11:42:36.925190Z","iopub.status.busy":"2024-04-16T11:42:36.924604Z","iopub.status.idle":"2024-04-16T11:42:36.943626Z","shell.execute_reply":"2024-04-16T11:42:36.942811Z","shell.execute_reply.started":"2024-04-16T11:42:36.925159Z"},"trusted":true},"outputs":[],"source":["def make_vgg19_model(input_shape, num_classes):\n","    inputs = keras.Input(shape=input_shape)\n","\n","    # Block 1\n","   # x = data_augmentation(inputs)\n","    x = layers.Rescaling(1.0 / 255)(inputs)\n","    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","\n","    # Block 2\n","    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","\n","    # Block 3\n","    x = layers.Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","    # Block 4\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","    # Block 5\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.MaxPooling2D((2, 2), strides=(2, 2))(x)\n","\n","    # Flatten and Fully Connected Layers\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(4096, activation='relu')(x)\n","    x = layers.Dropout(0.5)(x)\n","    x = layers.Dense(4096, activation='relu')(x)\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(num_classes, activation='softmax')(x)\n","\n","    return keras.Model(inputs, outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T11:42:36.944933Z","iopub.status.busy":"2024-04-16T11:42:36.944675Z","iopub.status.idle":"2024-04-16T12:43:06.308148Z","shell.execute_reply":"2024-04-16T12:43:06.307224Z","shell.execute_reply.started":"2024-04-16T11:42:36.944904Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","num_epochs = 5\n","\n","models = {\n","    \"AlexNet\": make_alexnet_model(input_shape=image_size, num_classes=num_classes),\n","    # \"VGG16\": make_vgg16_model(input_shape=image_size, num_classes=num_classes),\n","    # \"VGG19\": make_vgg19_model(input_shape=image_size, num_classes=num_classes),\n","}\n","\n","model_histories = {}\n","\n","for name, model in models.items():\n","    print(f'\\x1b[34mTraining {name} Model...\\x1b[0m')\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(1e-4),\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"],\n","    )\n","    start = time.time()\n","        \n","    # Wrap model.fit with tqdm for a progress bar\n","    progress_bar = tqdm(total=num_epochs, position=0, leave=True)\n","    history = model.fit(\n","        train_dataset,\n","        epochs=num_epochs,\n","        validation_data=val_dataset,\n","        verbose=1,\n","        callbacks=[\n","            tf.keras.callbacks.LambdaCallback(on_epoch_end=lambda epoch, logs: progress_bar.update(1)),\n","        ]\n","    )\n","    progress_bar.close()\n","    \n","    model_histories[name] = history\n","    \n","    end = time.time()\n","    print(f'Finished training {name} in {end-start:.2f}s\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T12:43:06.310134Z","iopub.status.busy":"2024-04-16T12:43:06.309670Z","iopub.status.idle":"2024-04-16T12:43:06.318691Z","shell.execute_reply":"2024-04-16T12:43:06.317684Z","shell.execute_reply.started":"2024-04-16T12:43:06.310099Z"},"trusted":true},"outputs":[],"source":["def plot_model_performance(name, history):\n","    acc = history.history['accuracy']\n","    val_acc = history.history['val_accuracy']\n","\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","\n","    epochs_range = range(num_epochs)\n","\n","    plt.figure(figsize=(20, 8))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs_range, acc, label='Training Accuracy')\n","    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","    plt.legend(loc='lower right')\n","    plt.title('Training and Validation Accuracy')\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs_range, loss, label='Training Loss')\n","    plt.plot(epochs_range, val_loss, label='Validation Loss')\n","    plt.legend(loc='upper right')\n","    plt.title('Training and Validation Loss')\n","    plt.suptitle(f'{name} Model Results')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T12:43:06.320031Z","iopub.status.busy":"2024-04-16T12:43:06.319784Z","iopub.status.idle":"2024-04-16T12:43:08.446344Z","shell.execute_reply":"2024-04-16T12:43:08.445410Z","shell.execute_reply.started":"2024-04-16T12:43:06.320009Z"},"trusted":true},"outputs":[],"source":["for name, history in model_histories.items():\n","    plot_model_performance(name, history)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T12:43:08.450427Z","iopub.status.busy":"2024-04-16T12:43:08.449811Z","iopub.status.idle":"2024-04-16T12:44:24.959341Z","shell.execute_reply":"2024-04-16T12:44:24.958325Z","shell.execute_reply.started":"2024-04-16T12:43:08.450391Z"},"trusted":true},"outputs":[],"source":["model_results = {}\n","\n","for name, model in models.items():\n","    model_results[name] = model.evaluate(test_dataset)\n","\n","    print(f'\\x1b[34m{name} Model Results:\\x1b[0m')\n","    print(f\"Test accuracy: {model_results[name][1]*100:.2f}%\")\n","    print(f\"Test loss: {model_results[name][0]:.4f}\", end = '\\n\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","def plot_confusion_matrix(name, model, val_dataset):\n","    true_labels = []\n","    predicted_labels = []\n","    for images, labels in val_dataset:\n","        true_labels.extend(labels.numpy())\n","        predictions = np.argmax(model.predict(images, verbose = 0), axis=1)\n","        predicted_labels.extend(predictions)\n","\n","    cm = confusion_matrix(true_labels, predicted_labels)\n","    \n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n","    plt.title(f'Confusion Matrix - {name} Model')\n","    plt.xlabel('Predicted Labels')\n","    plt.ylabel('True Labels')\n","    plt.show()\n","\n","for name, model in models.items():\n","    plot_confusion_matrix(name, model, val_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["alexnet_model = keras.models.load_model('Saved Models/AlexNet-93.32%.keras')\n","vgg16_model = keras.models.load_model('Saved Models/VGG16-94.73%.keras')\n","vgg19_model = keras.models.load_model('Saved Models/VGG19-92.67%.keras')\n","\n","class_to_test = 37 # Enter number from 0 to 37\n","img_to_test = 80\n","\n","img = keras.utils.load_img(\n","    f'New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/{class_names[class_to_test]}' + '/' + os.listdir(f'New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/{class_names[class_to_test]}')[img_to_test],    \n","    target_size=(224, 224)\n",")\n","img2 = keras.utils.load_img(\n","    f'test/test/AppleCedarRust3.JPG', target_size=(224,224)\n",")\n","plt.imshow(img)\n","plt.axis('off')\n","\n","img_array = keras.utils.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0)\n","\n","prediction = tf.argmax(alexnet_model.predict(img_array, verbose=0)[0]).numpy()\n","print(f'Predicted Class: {class_names[prediction]}\\nActual Class: {class_names[class_to_test]}')\n","prediction = tf.argmax(vgg16_model.predict(img_array, verbose=0)[0]).numpy()\n","print(f'Predicted Class: {class_names[prediction]}\\nActual Class: {class_names[class_to_test]}')\n","prediction = tf.argmax(vgg19_model.predict(img_array, verbose=0)[0]).numpy()\n","\n","plt.title(f'Predicted Class: {class_names[prediction]}\\nActual Class: {class_names[class_to_test]}')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":78313,"sourceId":182633,"sourceType":"datasetVersion"},{"modelInstanceId":4632,"sourceId":6095,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
